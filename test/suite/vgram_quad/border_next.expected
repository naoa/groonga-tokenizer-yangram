register tokenizers/yangram
[[0,0.0,0.0],true]
table_create vgram_words TABLE_HASH_KEY ShortText
[[0,0.0,0.0],true]
load --table vgram_words
[
{"_key": "デー"},
{"_key": "データ"}
]
[[0,0.0,0.0],2]
tokenize TokenYaVgramQuad "データベA処理" NormalizerAuto --mode ADD
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "データベ",
      "position": 0,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "ータ",
      "position": 1,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "タベ",
      "position": 2,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "ベ",
      "position": 3,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "a",
      "position": 4,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "処理",
      "position": 5,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "理",
      "position": 6,
      "force_prefix": false,
      "force_prefix_search": false
    }
  ]
]
tokenize TokenYaVgramQuad "データ" NormalizerAuto --mode GET
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "データ",
      "position": 0,
      "force_prefix": true,
      "force_prefix_search": true
    }
  ]
]
